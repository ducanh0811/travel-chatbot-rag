import os
import json
from dotenv import load_dotenv

from langchain.schema import Document
from langchain_community.vectorstores import Chroma
from langchain_community.vectorstores.utils import filter_complex_metadata
from langchain_openai import OpenAIEmbeddings

# ====== Load API Key ======
load_dotenv()
openai_api_key = os.environ.get("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("‚ö†Ô∏è Vui l√≤ng ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng OPENAI_API_KEY trong file .env c·ªßa b·∫°n.")

# ====== Load & G·ªôp d·ªØ li·ªáu t·ª´ 4 file JSON ======
def load_all_data():
    """
    ƒê·ªçc c√°c file JSON c·ªßa hotel, restaurant, destination, cafe v√† tr·∫£ v·ªÅ list Document.
    Metadata tags ƒë·ªÉ d∆∞·ªõi d·∫°ng list ban ƒë·∫ßu, s·∫Ω l·ªçc sau.
    """
    file_paths = {
        "hotel": "data/hotel.json",
        "restaurant": "data/restaurant.json",
        "destination": "data/destination.json",
        "cafe": "data/cafe.json"
    }
    documents = []
    for data_type, path in file_paths.items():
        if not os.path.exists(path):
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file: {path}")
            continue
        with open(path, "r", encoding="utf-8") as f:
            items = json.load(f)
        for item in items:
            name = item.get("name", "Kh√¥ng r√µ")
            desc = item.get("description", "")
            district = item.get("district", "")
            ward = item.get("ward", "")
            if data_type == "hotel":
                open_time = item.get("checkin_time", "Kh√¥ng r√µ")
                close_time = item.get("checkout_time", "Kh√¥ng r√µ")
            else:
                open_time = item.get("open_time", "")
                close_time = item.get("close_time", "")
            tags = item.get("tags", [])
            suggested = item.get("duration_suggested_min", "Kh√¥ng r√µ")
            content = (
                f"{name} ({data_type}) - ph∆∞·ªùng {ward}, qu·∫≠n {district}. "
                f"M√¥ t·∫£: {desc}. "
                f"Gi·ªù m·ªü: {open_time}, ƒë√≥ng: {close_time}. "
                f"Th·ªùi gian g·ª£i √Ω: {suggested} ph√∫t. "
                f"Tags: {', '.join(tags)}"
            )
            doc = Document(
                page_content=content,
                metadata={
                    "type": data_type,
                    "name": name,
                    "district": district or None,
                    "ward": ward or None,
                    "tags": tags
                }
            )
            documents.append(doc)
    return documents

# ====== T·∫°o v√† L∆∞u ChromaDB ======
def save_chromadb(documents, persist_dir: str = "chromadb"):
    """
    T·∫°o vector store ChromaDB t·ª´ danh s√°ch Document v√† l∆∞u v√†o persist_dir.
    √Åp d·ª•ng filter_complex_metadata ƒë·ªÉ lo·∫°i b·ªè metadata ph·ª©c t·∫°p.
    """
    # Lo·∫°i b·ªè metadata ph·ª©c t·∫°p (list, dict)
    simple_docs = filter_complex_metadata(documents)

    embedding = OpenAIEmbeddings(openai_api_key=openai_api_key)
    chroma_store = Chroma.from_documents(
        documents=simple_docs,
        embedding=embedding,
        persist_directory=persist_dir
    ) 
    print(f"‚úÖ ƒê√£ l∆∞u ChromaDB v√†o th∆∞ m·ª•c: {persist_dir}")
    return chroma_store

# ====== Main ======
if __name__ == "__main__":
    print("üîÑ B·∫Øt ƒë·∫ßu t·∫£i d·ªØ li·ªáu...")
    docs = load_all_data()
    print(f"üìÑ T·ªïng s·ªë Document: {len(docs)}")
    print("üíæ L∆∞u ChromaDB...")
    save_chromadb(docs)
    print("üéâ Ho√†n th√†nh!")
