import os
import json
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor
from langchain.schema import Document
from langchain_community.vectorstores import Chroma
from langchain_community.vectorstores.utils import filter_complex_metadata
from langchain_openai import OpenAIEmbeddings

# ====== Load API Key ======
load_dotenv()
openai_api_key = os.environ.get("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("‚ö†Ô∏è Vui l√≤ng ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng OPENAI_API_KEY trong file .env c·ªßa b·∫°n.")

# ====== Load & G·ªôp d·ªØ li·ªáu t·ª´ 4 file JSON song song ======
def load_file_data(data_type, path):
    if not os.path.exists(path):
        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file: {path}")
        return []
    with open(path, "r", encoding="utf-8") as f:
        items = json.load(f)
    docs = []
    for item in items:
        name = item.get("name", "Kh√¥ng r√µ")
        desc = item.get("description", "")
        district = item.get("district", "")
        type = item.get("type", "")
        ward = item.get("ward", "")
        if data_type == "hotel":
            open_time = item.get("checkin_time", "Kh√¥ng r√µ")
            close_time = item.get("checkout_time", "Kh√¥ng r√µ")
        else:
            open_time = item.get("open_time", "")
            close_time = item.get("close_time", "")
        tags = item.get("tags", [])
        suggested = item.get("duration_suggested_min", "Kh√¥ng r√µ")
        content = (
            f"{name} ({data_type}) - ph∆∞·ªùng {ward}, qu·∫≠n {district}. "
            f"Lo·∫°i: {type}. "
            f"M√¥ t·∫£: {desc}. "
            f"Gi·ªù m·ªü: {open_time}, ƒë√≥ng: {close_time}. "
            f"Th·ªùi gian g·ª£i √Ω: {suggested} ph√∫t. "
            f"Tags: {', '.join(tags)}"
        )
        doc = Document(
            page_content=content,
            metadata={
                "type": type,
                "name": name,
                "district": district or None,
                "ward": ward or None,
                "tags": tags
            }
        )
        docs.append(doc)
    return docs

def load_all_data():
    file_paths = {
        "hotel": "data/hotel.json",
        "restaurant": "data/restaurant.json",
        "destination": "data/destination.json",
        "cafe": "data/cafe.json"
    }
    documents = []
    with ThreadPoolExecutor() as executor:
        futures = [executor.submit(load_file_data, data_type, path) for data_type, path in file_paths.items()]
        for future in futures:
            documents.extend(future.result())
    return documents

# ====== T·∫°o v√† L∆∞u ChromaDB ======
def save_chromadb(documents, persist_dir: str = "chromadb"):
    """
    T·∫°o vector store ChromaDB t·ª´ danh s√°ch Document v√† l∆∞u v√†o persist_dir.
    √Åp d·ª•ng filter_complex_metadata ƒë·ªÉ lo·∫°i b·ªè metadata ph·ª©c t·∫°p.
    """
    # Lo·∫°i b·ªè metadata ph·ª©c t·∫°p (list, dict)
    simple_docs = filter_complex_metadata(documents)
    embedding = OpenAIEmbeddings(openai_api_key=openai_api_key)
    chroma_store = Chroma.from_documents(
        documents=simple_docs,
        embedding=embedding,
        persist_directory=persist_dir
    ) 
    print(f"‚úÖ ƒê√£ l∆∞u ChromaDB v√†o th∆∞ m·ª•c: {persist_dir}")
    return chroma_store

# ====== Main ======
if __name__ == "__main__":
    print("üîÑ B·∫Øt ƒë·∫ßu t·∫£i d·ªØ li·ªáu...")
    docs = load_all_data()
    print(f"üìÑ T·ªïng s·ªë Document: {len(docs)}")
    print("üíæ L∆∞u ChromaDB...")
    save_chromadb(docs)
    print("üéâ Ho√†n th√†nh!")
