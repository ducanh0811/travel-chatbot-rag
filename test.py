import os
import json
from dotenv import load_dotenv
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document
from langchain.chains import RetrievalQA
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.prompts import PromptTemplate
# ====== Load API Key ======
load_dotenv()
openai_api_key = os.environ["OPENAI_API_KEY"]

# ====== Load & Gá»™p dá»¯ liá»‡u tá»« 4 file JSON ======
def load_all_data():
    file_paths = {
        "hotel": "data/hotel.json",
        "restaurant": "data/restaurant.json",
        "destination": "data/destination.json",
        "cafe": "data/cafe.json"
    }

    all_docs = []
    for data_type, path in file_paths.items():
        if not os.path.exists(path):
            print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y file: {path}")
            continue

        with open(path, "r", encoding="utf-8") as f:
            items = json.load(f)

            for item in items:
                name = item.get("name", "KhÃ´ng rÃµ")
                desc = item.get("description", "")
                district = item.get("district", "")
                ward = item.get("ward", "")
                if data_type == "hotel":
                    open_time = item.get("checkin_time", "KhÃ´ng rÃµ")
                    close_time = item.get("checkout_time", "KhÃ´ng rÃµ")
                else:
                    open_time = item.get("open_time", "")
                    close_time = item.get("close_time", "")
                tags = ", ".join(item.get("tags", []))
                duration = item.get("duration_suggested_min", "KhÃ´ng rÃµ")

                content = (
                    f"{name} lÃ  má»™t {data_type} náº±m á»Ÿ phÆ°á»ng {ward}, quáº­n {district}. "
                    f"MÃ´ táº£: {desc} "
                    f"Má»Ÿ cá»­a tá»« {open_time} Ä‘áº¿n {close_time}. "
                    f"Gá»£i Ã½ thá»i gian tham quan: khoáº£ng {duration} phÃºt. "
                    f"Tá»« khÃ³a liÃªn quan: {tags}."
                )

                doc = Document(
                    page_content=content,
                    metadata={
                        "type": data_type,
                        "name": name,
                        "district": str(item.get("district", "")) if item.get("district") else None,
                        "ward": str(item.get("ward", "")) if item.get("ward") else None,
                        "tags": ", ".join(item.get("tags", []))
                    }
                )
                all_docs.append(doc)
    return all_docs
#======HÃ m lá»c theo metadata(ward, district) =====
def get_retriever_with_filters(vectorstore, district=None, ward=None):
    filters = {}

    if district:
        filters["district"] = district
    if ward:
        filters["ward"] = ward
    if filters:
        retriever = vectorstore.as_retriever(
            search_type="mmr",
            search_kwargs={
                "k": 5,
                "filter": filters
            }
        )
    else:
        retriever = vectorstore.as_retriever(
            search_type="mmr",
            search_kwargs={"k": 5}
        )
    return retriever
# ====== Táº¡o Embedding vÃ  lÆ°u vÃ o ChromaDB ======
def create_vector_store(documents):
    embedding = OpenAIEmbeddings(openai_api_key=openai_api_key)
    vectorstore = Chroma.from_documents(
        documents=documents,
        embedding=embedding,
        persist_directory="chromadb"
    )
    vectorstore.persist()
    return vectorstore

# ====== Truy váº¥n vá»›i LangChain ======
def build_chatbot(vectorstore, district=None, ward=None):
    retriever = get_retriever_with_filters(vectorstore, district, ward)
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        openai_api_key=openai_api_key,
        temperature=0.7  # Gá»£i Ã½ Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i phong phÃº hÆ¡n
    )

    # chain = RetrievalQA.from_chain_type(
    #     llm=llm,
    #     retriever=retriever,
    #     return_source_documents=False
    # )
    QA_PROMPT = PromptTemplate.from_template("""
    Báº¡n lÃ  má»™t hÆ°á»›ng dáº«n viÃªn du lá»‹ch thÃ´ng minh. Tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng báº±ng tiáº¿ng Viá»‡t, dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p tá»« dá»¯ liá»‡u truy xuáº¥t.

    â— Náº¿u ngÆ°á»i dÃ¹ng há»i gá»£i Ã½, hÃ£y trÃ¬nh bÃ y theo format sau:

    TÃªn: ...
    Loáº¡i: ...
    Khu vá»±c: ...
    â— Náº¿u ngÆ°á»i dÃ¹ng nÃ³i "chi tiáº¿t hÆ¡n" hoáº·c "xem thÃªm", hÃ£y má»Ÿ rá»™ng mÃ´ táº£ vÃ  Ä‘Æ°a thÃªm cÃ¡c Ä‘iá»ƒm ná»•i báº­t.

    CÃ¢u há»i: {question}
    ThÃ´ng tin há»— trá»£: {context}
    Tráº£ lá»i:
    """)

    chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        return_source_documents=False,
        chain_type_kwargs={"prompt": QA_PROMPT}
    )    
    return chain



# ====== MAIN ======
if __name__ == "__main__":
    print("ğŸ”„ Äang táº£i dá»¯ liá»‡u...")
    documents = load_all_data()

    print(f"ğŸ“„ ÄÃ£ táº£i {len(documents)} Ä‘á»‹a Ä‘iá»ƒm.")
    print("ğŸ’¾ Äang táº¡o vector store...")
    vectorstore = create_vector_store(documents)

    print("ğŸ¤– Khá»Ÿi Ä‘á»™ng chatbot...")
    chatbot = build_chatbot(vectorstore)

    print("âœ… Chatbot Ä‘Ã£ sáºµn sÃ ng! GÃµ 'exit' Ä‘á»ƒ thoÃ¡t.")
    history = []
    while True:
        user_input = input("ğŸ’¬ Báº¡n: ").strip()
        if user_input in ["chi tiáº¿t hÆ¡n", "xem thÃªm", "nÃ³i rÃµ hÆ¡n", "tell me more"]:
                if history:
                    user_input = f"Cho tÃ´i biáº¿t chi tiáº¿t hÆ¡n vá» {history[-1]}"
                else:
                    print("ğŸ¤– Bot: Báº¡n muá»‘n biáº¿t chi tiáº¿t vá» gÃ¬?")
                    continue
        else:
                history.append(user_input)

        result = chatbot.invoke({"query": user_input})
        print("ğŸ¤– Bot:", result["result"])