import os
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain.chains import RetrievalQA
from langchain.tools import tool
from langchain.prompts import PromptTemplate
from concurrent.futures import ThreadPoolExecutor

def load_env():
    load_dotenv()
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("âš ï¸ Vui lÃ²ng thiáº¿t láº­p biáº¿n mÃ´i trÆ°á»ng OPENAI_API_KEY trong .env")
    return api_key

def get_embedding_and_vectorstore():
    # Khá»Ÿi táº¡o embedding vÃ  vectorstore song song
    with ThreadPoolExecutor() as executor:
        future_embedding = executor.submit(OpenAIEmbeddings)
        embedding = future_embedding.result()
        future_vectorstore = executor.submit(
            lambda: Chroma(
                persist_directory="chromadb",
                embedding_function=embedding,
            )
        )
        vectorstore = future_vectorstore.result()
    return embedding, vectorstore

QA_PROMPT = PromptTemplate.from_template("""
    Báº¡n lÃ  má»™t hÆ°á»›ng dáº«n viÃªn du lá»‹ch thÃ´ng minh. Tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng báº±ng tiáº¿ng Viá»‡t, dá»±a trÃªn thÃ´ng tin tá»« dá»¯ liá»‡u Ä‘á»‹a Ä‘iá»ƒm bÃªn dÆ°á»›i.

    QUAN TRá»ŒNG:
    - Chá»‰ tráº£ lá»i Ä‘Ãºng loáº¡i Ä‘á»‹a Ä‘iá»ƒm mÃ  ngÆ°á»i dÃ¹ng há»i (vÃ­ dá»¥: chá»‰ khÃ¡ch sáº¡n náº¿u há»i khÃ¡ch sáº¡n, chá»‰ quÃ¡n cafe náº¿u há»i cafe, v.v.).
    - Æ¯u tiÃªn cÃ¡c Ä‘á»‹a Ä‘iá»ƒm cÃ³ tÃªn hoáº·c khu vá»±c trÃ¹ng khá»›p vá»›i truy váº¥n cá»§a ngÆ°á»i dÃ¹ng (vÃ­ dá»¥: náº¿u há»i vá» SÆ¡n TrÃ  thÃ¬ Æ°u tiÃªn cÃ¡c Ä‘á»‹a Ä‘iá»ƒm á»Ÿ khu vá»±c SÆ¡n TrÃ  hoáº·c cÃ³ tÃªn SÆ¡n TrÃ ).
    - KhÃ´ng gá»™p cÃ¡c loáº¡i Ä‘á»‹a Ä‘iá»ƒm khÃ¡c nhau vÃ o cÃ¹ng má»™t cÃ¢u tráº£ lá»i.
    - Náº¿u khÃ´ng tÃ¬m tháº¥y Ä‘á»‹a Ä‘iá»ƒm phÃ¹ há»£p, hÃ£y tráº£ lá»i rÃµ rÃ ng lÃ  khÃ´ng cÃ³ káº¿t quáº£ phÃ¹ há»£p.
    
    Má»—i gá»£i Ã½ trÃ¬nh bÃ y theo máº«u:
                                       
    TÃªn: (TÃªn Ä‘á»‹a Ä‘iá»ƒm)  
    Loáº¡i: (Loáº¡i Ä‘á»‹a Ä‘iá»ƒm: quÃ¡n Äƒn, cafe, khÃ¡ch sáº¡n...)  
    Khu vá»±c: (PhÆ°á»ng, Quáº­n)  
    MÃ´ táº£: (MÃ´ táº£ ngáº¯n gá»n, háº¥p dáº«n, ná»•i báº­t)  
    Thá»i gian má»Ÿ Ä‘Ã³ng: (Open-Close)/(Checkin/Checkout)
    Thá»i gian gá»£i Ã½ á»Ÿ láº¡i: (Duration_suggested_min) <Hotel thÃ¬ bá» qua>
    -----------------------------------------------

    Náº¿u ngÆ°á»i dÃ¹ng yÃªu cáº§u chi tiáº¿t hÆ¡n, báº¡n cÃ³ thá»ƒ mÃ´ táº£ sÃ¢u hÆ¡n vá» cÃ¡c dá»‹ch vá»¥, giá» má»Ÿ cá»­a, phÃ¹ há»£p vá»›i nhÃ³m nÃ o, v.v.

    CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: {question}  
    Dá»¯ liá»‡u Ä‘á»‹a Ä‘iá»ƒm truy xuáº¥t Ä‘Æ°á»£c:  
    {context}

    Tráº£ lá»i:
    """)

# Khá»Ÿi táº¡o embedding vÃ  vectorstore toÃ n cá»¥c (cÃ³ thá»ƒ dÃ¹ng láº¡i)
load_env()
embedding, vectorstore = get_embedding_and_vectorstore()

@tool
def rag_tool(query: str) -> str:
    """
    Tráº£ lá»i cÃ¢u há»i dá»±a trÃªn vectorstore Ä‘Ã£ khá»Ÿi táº¡o tá»« ChromaDB.
    Vectorstore pháº£i Ä‘Æ°á»£c gÃ¡n trÆ°á»›c khi gá»i tool nÃ y.
    """
    global vectorstore
    if vectorstore is None:
        raise ValueError("Vectorstore chÆ°a Ä‘Æ°á»£c gÃ¡n. Vui lÃ²ng khá»Ÿi táº¡o trong Agent vÃ  gÃ¡n vÃ o rag_tool_module.vectorstore.")
    retriever = vectorstore.as_retriever(search_type="mmr", search_kwargs={"k": 5})
    qa_chain = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(model="gpt-4o-mini", temperature=0),
        retriever=retriever,
        return_source_documents=False,
        chain_type_kwargs={"prompt": QA_PROMPT}
    )
    return qa_chain.invoke(query)["result"]

if __name__ == "__main__":
    test_query = "Gá»£i Ã½ nhÃ  hÃ ng 3 sao gáº§n biá»ƒn"
    print("âš™ï¸ Thá»±c thi rag_tool vá»›i query:\n", test_query)
    try:
        result = rag_tool(test_query)
        print("ğŸ¤– Káº¿t quáº£:\n", result)
    except Exception as e:
        print("âŒ Lá»—i khi cháº¡y rag_tool:", e)

