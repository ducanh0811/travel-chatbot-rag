import os
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.tools import tool
from langchain.prompts import PromptTemplate
# ====== Load API Key ======
load_dotenv()
openai_api_key = os.environ.get("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("‚ö†Ô∏è Vui l√≤ng thi·∫øt l·∫≠p bi·∫øn m√¥i tr∆∞·ªùng OPENAI_API_KEY trong .env")

# ====== Vectorstore s·∫Ω ƒë∆∞·ª£c g√°n t·ª´ Agent ch√≠nh ======
embedding = OpenAIEmbeddings()
vectorstore = Chroma(
persist_directory="chromadb",
embedding_function=embedding,
)
QA_PROMPT = PromptTemplate.from_template("""
    B·∫°n l√† m·ªôt h∆∞·ªõng d·∫´n vi√™n du l·ªãch th√¥ng minh. Tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng b·∫±ng ti·∫øng Vi·ªát, d·ª±a tr√™n th√¥ng tin t·ª´ d·ªØ li·ªáu ƒë·ªãa ƒëi·ªÉm b√™n d∆∞·ªõi.

    N·∫øu ng∆∞·ªùi d√πng c·∫ßn g·ª£i √Ω, h√£y ƒë∆∞a ra 5 ƒë·ªãa ƒëi·ªÉm ph√π h·ª£p nh·∫•t. M·ªói g·ª£i √Ω tr√¨nh b√†y theo m·∫´u:
                                       
    T√™n: (T√™n ƒë·ªãa ƒëi·ªÉm)  
    Lo·∫°i: (Lo·∫°i ƒë·ªãa ƒëi·ªÉm: qu√°n ƒÉn, cafe, kh√°ch s·∫°n...)  
    Khu v·ª±c: (Ph∆∞·ªùng, Qu·∫≠n)  
    M√¥ t·∫£: (M√¥ t·∫£ ng·∫Øn g·ªçn, h·∫•p d·∫´n, n·ªïi b·∫≠t)  
    ---

    N·∫øu ng∆∞·ªùi d√πng y√™u c·∫ßu chi ti·∫øt h∆°n, b·∫°n c√≥ th·ªÉ m√¥ t·∫£ s√¢u h∆°n v·ªÅ c√°c d·ªãch v·ª•, gi·ªù m·ªü c·ª≠a, ph√π h·ª£p v·ªõi nh√≥m n√†o, v.v.

    C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {question}  
    D·ªØ li·ªáu ƒë·ªãa ƒëi·ªÉm truy xu·∫•t ƒë∆∞·ª£c:  
    {context}

    Tr·∫£ l·ªùi:
    """)
@tool
def rag_tool(query: str) -> str:
    """
    Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n vectorstore ƒë√£ kh·ªüi t·∫°o t·ª´ ChromaDB.
    Vectorstore ph·∫£i ƒë∆∞·ª£c g√°n tr∆∞·ªõc khi g·ªçi tool n√†y.
    """
    global vectorstore
    if vectorstore is None:
        raise ValueError("Vectorstore ch∆∞a ƒë∆∞·ª£c g√°n. Vui l√≤ng kh·ªüi t·∫°o trong Agent v√† g√°n v√†o rag_tool_module.vectorstore.")
    # T·∫°o retriever
    retriever = vectorstore.as_retriever(search_type="mmr", search_kwargs={"k": 5})
    # T·∫°o QA chain
    qa_chain = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(model="gpt-3.5-turbo",temperature=0),
        retriever=retriever,
        return_source_documents=False,
        chain_type_kwargs={"prompt": QA_PROMPT}
    )
    # Th·ª±c thi truy v·∫•n
    return qa_chain.invoke(query)["result"]
if __name__ == "__main__":
    # Th·ª≠ nghi·ªám
    test_query = "G·ª£i √Ω nh√† h√†ng 3 sao g·∫ßn bi·ªÉn"
    print("‚öôÔ∏è Th·ª±c thi rag_tool v·ªõi query:\n", test_query)
    try:
        result = rag_tool(test_query)
        print("ü§ñ K·∫øt qu·∫£:\n", result)
    except Exception as e:
        print("‚ùå L·ªói khi ch·∫°y rag_tool:", e)

